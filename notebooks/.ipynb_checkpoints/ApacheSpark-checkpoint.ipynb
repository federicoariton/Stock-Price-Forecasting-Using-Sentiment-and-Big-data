{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac3b510-8b65-457f-acbe-b8869eb598b6",
   "metadata": {},
   "source": [
    "# Federico Ariton\n",
    "# Master of Science in Data Analytics\n",
    "# Semester 2 - CA2 Integreated\n",
    "# Student Number: sba22090\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e344ff09-40c9-4c34-8f44-60e55df2ea2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 items\n",
      "-rw-r--r--   1 hduser supergroup      27598 2025-04-29 10:04 /stock-tweet-and-price/stockprice/AAPL.csv\n",
      "-rw-r--r--   1 hduser supergroup       1475 2025-04-29 10:04 /stock-tweet-and-price/stockprice/ABNB.csv\n",
      "-rw-r--r--   1 hduser supergroup      27440 2025-04-29 10:04 /stock-tweet-and-price/stockprice/AMT.csv\n",
      "-rw-r--r--   1 hduser supergroup      27756 2025-04-29 10:04 /stock-tweet-and-price/stockprice/AMZN.csv\n",
      "-rw-r--r--   1 hduser supergroup      27146 2025-04-29 10:04 /stock-tweet-and-price/stockprice/BA.csv\n",
      "-rw-r--r--   1 hduser supergroup      27341 2025-04-29 10:04 /stock-tweet-and-price/stockprice/BABA.csv\n",
      "-rw-r--r--   1 hduser supergroup      28475 2025-04-29 10:04 /stock-tweet-and-price/stockprice/BAC.csv\n",
      "-rw-r--r--   1 hduser supergroup      25665 2025-04-29 10:04 /stock-tweet-and-price/stockprice/BKNG.csv\n",
      "-rw-r--r--   1 hduser supergroup      15550 2025-04-29 10:04 /stock-tweet-and-price/stockprice/BRK-A.csv\n",
      "-rw-r--r--   1 hduser supergroup      27910 2025-04-29 10:04 /stock-tweet-and-price/stockprice/BRK-B.csv\n",
      "-rw-r--r--   1 hduser supergroup      28037 2025-04-29 10:04 /stock-tweet-and-price/stockprice/CCL.csv\n",
      "-rw-r--r--   1 hduser supergroup      27300 2025-04-29 10:04 /stock-tweet-and-price/stockprice/CVX.csv\n",
      "-rw-r--r--   1 hduser supergroup      28041 2025-04-29 10:04 /stock-tweet-and-price/stockprice/DIS.csv\n",
      "-rw-r--r--   1 hduser supergroup      27475 2025-04-29 10:04 /stock-tweet-and-price/stockprice/FB.csv\n",
      "-rw-r--r--   1 hduser supergroup      27640 2025-04-29 10:04 /stock-tweet-and-price/stockprice/GOOG.csv\n",
      "-rw-r--r--   1 hduser supergroup      27478 2025-04-29 10:04 /stock-tweet-and-price/stockprice/GOOGL.csv\n",
      "-rw-r--r--   1 hduser supergroup      27542 2025-04-29 10:04 /stock-tweet-and-price/stockprice/HD.csv\n",
      "-rw-r--r--   1 hduser supergroup      27755 2025-04-29 10:04 /stock-tweet-and-price/stockprice/JNJ.csv\n",
      "-rw-r--r--   1 hduser supergroup      27724 2025-04-29 10:04 /stock-tweet-and-price/stockprice/JPM.csv\n",
      "-rw-r--r--   1 hduser supergroup      27736 2025-04-29 10:04 /stock-tweet-and-price/stockprice/KO.csv\n",
      "-rw-r--r--   1 hduser supergroup      27836 2025-04-29 10:04 /stock-tweet-and-price/stockprice/LOW.csv\n",
      "-rw-r--r--   1 hduser supergroup      26949 2025-04-29 10:04 /stock-tweet-and-price/stockprice/MA.csv\n",
      "-rw-r--r--   1 hduser supergroup      27679 2025-04-29 10:04 /stock-tweet-and-price/stockprice/MCD.csv\n",
      "-rw-r--r--   1 hduser supergroup      27475 2025-04-29 10:04 /stock-tweet-and-price/stockprice/META.csv\n",
      "-rw-r--r--   1 hduser supergroup      27970 2025-04-29 10:04 /stock-tweet-and-price/stockprice/MSFT.csv\n",
      "-rw-r--r--   1 hduser supergroup      26316 2025-04-29 10:04 /stock-tweet-and-price/stockprice/NFLX.csv\n",
      "-rw-r--r--   1 hduser supergroup      27229 2025-04-29 10:04 /stock-tweet-and-price/stockprice/NKE.csv\n",
      "-rw-r--r--   1 hduser supergroup      27140 2025-04-29 10:04 /stock-tweet-and-price/stockprice/NVDA.csv\n",
      "-rw-r--r--   1 hduser supergroup      28553 2025-04-29 10:04 /stock-tweet-and-price/stockprice/PFE.csv\n",
      "-rw-r--r--   1 hduser supergroup      28088 2025-04-29 10:04 /stock-tweet-and-price/stockprice/PG.csv\n",
      "-rw-r--r--   1 hduser supergroup      27651 2025-04-29 10:04 /stock-tweet-and-price/stockprice/PYPL.csv\n",
      "-rw-r--r--   1 hduser supergroup      27139 2025-04-29 10:04 /stock-tweet-and-price/stockprice/SBUX.csv\n",
      "-rw-r--r--   1 hduser supergroup      27517 2025-04-29 10:04 /stock-tweet-and-price/stockprice/TM.csv\n",
      "-rw-r--r--   1 hduser supergroup      28347 2025-04-29 10:04 /stock-tweet-and-price/stockprice/TSLA.csv\n",
      "-rw-r--r--   1 hduser supergroup      27357 2025-04-29 10:04 /stock-tweet-and-price/stockprice/TSM.csv\n",
      "-rw-r--r--   1 hduser supergroup      27009 2025-04-29 10:04 /stock-tweet-and-price/stockprice/UNH.csv\n",
      "-rw-r--r--   1 hduser supergroup      27579 2025-04-29 10:04 /stock-tweet-and-price/stockprice/UPS.csv\n",
      "-rw-r--r--   1 hduser supergroup      27650 2025-04-29 10:04 /stock-tweet-and-price/stockprice/V.csv\n",
      "-rw-r--r--   1 hduser supergroup      28120 2025-04-29 10:04 /stock-tweet-and-price/stockprice/WMT.csv\n",
      "-rw-r--r--   1 hduser supergroup      27924 2025-04-29 10:04 /stock-tweet-and-price/stockprice/XOM.csv\n",
      "Found 1 items\n",
      "-rw-r--r--   1 hduser supergroup    1126042 2025-04-29 10:03 /stock-tweet-and-price/stocktweet/stocktweet.csv\n"
     ]
    }
   ],
   "source": [
    "# Check inside stockprice\n",
    "!hdfs dfs -ls /stock-tweet-and-price/stockprice\n",
    "\n",
    "# Check inside stocktweet\n",
    "!hdfs dfs -ls /stock-tweet-and-price/stocktweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca4316e-831b-4b15-8aff-7c99b9d4d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lower, regexp_replace, avg, count, lit, when, lag, stddev\n",
    "from pyspark.sql.types import FloatType\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f49fe-2b7d-4a8b-a56e-a251031dfe65",
   "metadata": {},
   "source": [
    "## Spark Session and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355875e8-a1f4-4d13-a84c-b0dc2935463b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 13:47:03 WARN Utils: Your hostname, BDSP2025S21 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/05/02 13:47:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.4.4-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hduser/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hduser/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ac95ebe8-6ada-4d90-a4c7-9471b21ad3e0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.2.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.6 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.16.3 in central\n",
      ":: resolution report :: resolve 1635ms :: artifacts dl 33ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.6 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.2.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.16.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   85  |   0   |   0   |   5   ||   80  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ac95ebe8-6ada-4d90-a4c7-9471b21ad3e0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 80 already retrieved (0kB/26ms)\n",
      "25/05/02 13:47:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SentimentAnalysisWithSparkNLP\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.2.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4142110-48a3-40cd-a2be-5a3551afabfd",
   "metadata": {},
   "source": [
    "## Load annd Preprocess Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c46aab-d6e8-4eb3-ba78-5d1836ee5083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n",
      "+------+----------+------+--------------------+\n",
      "|    id|      date|ticker|               tweet|\n",
      "+------+----------+------+--------------------+\n",
      "|100001|01/01/2020|  AMZN|$AMZN Dow futures...|\n",
      "|100002|01/01/2020|  TSLA|$TSLA Daddy's dri...|\n",
      "|100003|01/01/2020|  AAPL|$AAPL We’ll been ...|\n",
      "|100004|01/01/2020|  TSLA|$TSLA happy new y...|\n",
      "|100005|01/01/2020|  TSLA|\"$TSLA haha just ...|\n",
      "+------+----------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tweets CSV\n",
    "tweets_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"hdfs:///stock-tweet-and-price/stocktweet/stocktweet.csv\")\n",
    "\n",
    "# Show schema and sample\n",
    "tweets_df.printSchema()\n",
    "tweets_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd649f37-8d91-4780-a8bc-e02f765d3c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+\n",
      "|ticker|date      |tweet                                                                                                                                      |tweet_clean                                                                                                               |\n",
      "+------+----------+-------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+\n",
      "|amzn  |2020-01-01|$AMZN Dow futures up by 100 points already 🥳                                                                                              |amzn dow futures up by  points already                                                                                    |\n",
      "|tsla  |2020-01-01|$TSLA Daddy's drinkin' eArly tonight! Here's to a PT of ohhhhh $1000 in 2020! 🍻                                                           |tsla daddys drinkin early tonight heres to a pt of ohhhhh  in                                                             |\n",
      "|aapl  |2020-01-01|$AAPL We’ll been riding since last December from $172.12 what to do. Decisions decisions hmm 🤔. I have 20 mins to decide. Any suggestions?|aapl well been riding since last december from  what to do decisions decisions hmm  i have  mins to decide any suggestions|\n",
      "|tsla  |2020-01-01|$TSLA happy new year, 2020, everyone🍷🎉🙏                                                                                                 |tsla happy new year  everyone                                                                                             |\n",
      "|tsla  |2020-01-01|\"$TSLA haha just a collection of greats...\"\"Mars\"\" rofl 😈😎🌠⏫🔮💸👏💪🚀🎆🎇📣🎉🎊 *bork*\"                                                |tsla haha just a collection of greatsmars rofl  bork                                                                      |\n",
      "+------+----------+-------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace, to_date\n",
    "\n",
    "# Remove $ and lowercase ticker\n",
    "tweets_df = tweets_df.withColumn(\"ticker\", regexp_replace(lower(col(\"ticker\")), \"\\\\$\", \"\"))\n",
    "\n",
    "# Clean tweet text\n",
    "tweets_df = tweets_df.withColumn(\"tweet_clean\", regexp_replace(lower(col(\"tweet\")), \"[^a-zA-Z\\\\s]\", \"\"))\n",
    "\n",
    "# CORRECT date parsing\n",
    "tweets_df = tweets_df.withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "# Show clean output\n",
    "tweets_df.select(\"ticker\", \"date\", \"tweet\", \"tweet_clean\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e668cd-d19e-4f22-ae05-d3ec4fe92bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- tweet_clean: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7371a3e2-9a41-4dd3-a034-89aeb0cd5076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+--------------------+--------------------+\n",
      "|    id|      date|ticker|               tweet|         tweet_clean|\n",
      "+------+----------+------+--------------------+--------------------+\n",
      "|100001|2020-01-01|  amzn|$AMZN Dow futures...|amzn dow futures ...|\n",
      "|100002|2020-01-01|  tsla|$TSLA Daddy's dri...|tsla daddys drink...|\n",
      "|100003|2020-01-01|  aapl|$AAPL We’ll been ...|aapl well been ri...|\n",
      "|100004|2020-01-01|  tsla|$TSLA happy new y...|tsla happy new ye...|\n",
      "|100005|2020-01-01|  tsla|\"$TSLA haha just ...|tsla haha just a ...|\n",
      "+------+----------+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17641fc5-de14-4a85-bdc4-230eb517b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp in /home/hduser/miniconda3/lib/python3.12/site-packages (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spark-nlp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc50c9-ad19-48fc-8edb-ef5d58b33756",
   "metadata": {},
   "source": [
    "## Sentimental Analysis Using Spark NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db810976-2b75-48d3-8ba2-1b591f8b87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_vivekn download started this may take some time.\n",
      "Approximate size to download 873.6 KB\n",
      "[ \\ ]sentiment_vivekn download started this may take some time.\n",
      "Approximate size to download 873.6 KB\n",
      "[ / ]Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:============================================>            (63 + 1) / 80]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|tweet                                                                                                                                      |result    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|$AMZN Dow futures up by 100 points already 🥳                                                                                              |[negative]|\n",
      "|$TSLA Daddy's drinkin' eArly tonight! Here's to a PT of ohhhhh $1000 in 2020! 🍻                                                           |[negative]|\n",
      "|$AAPL We’ll been riding since last December from $172.12 what to do. Decisions decisions hmm 🤔. I have 20 mins to decide. Any suggestions?|[positive]|\n",
      "|$TSLA happy new year, 2020, everyone🍷🎉🙏                                                                                                 |[negative]|\n",
      "|\"$TSLA haha just a collection of greats...\"\"Mars\"\" rofl 😈😎🌠⏫🔮💸👏💪🚀🎆🎇📣🎉🎊 *bork*\"                                                |[negative]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, ViveknSentimentModel\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Step 1: Convert to document\n",
    "document = DocumentAssembler() \\\n",
    "    .setInputCol(\"tweet_clean\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Step 2: Tokenize\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Step 3: Apply pretrained sentiment model\n",
    "sentiment = ViveknSentimentModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[document, tokenizer, sentiment])\n",
    "\n",
    "# Fit and apply\n",
    "model = pipeline.fit(tweets_df)\n",
    "result = model.transform(tweets_df)\n",
    "\n",
    "# Show results\n",
    "result.select(\"tweet\", \"sentiment.result\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a9a62-8e4e-4377-bd85-e1930894e396",
   "metadata": {},
   "source": [
    "## Extract Sentiment Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45c9a1-0d29-435c-b4cb-e41372dcec7f",
   "metadata": {},
   "source": [
    "## Extract Sentiment Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349b4441-b8cd-46c6-a1f9-c62adecd5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|tweet                                                                                                                                      |sentiment_label|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|$AMZN Dow futures up by 100 points already 🥳                                                                                              |negative       |\n",
      "|$TSLA Daddy's drinkin' eArly tonight! Here's to a PT of ohhhhh $1000 in 2020! 🍻                                                           |negative       |\n",
      "|$AAPL We’ll been riding since last December from $172.12 what to do. Decisions decisions hmm 🤔. I have 20 mins to decide. Any suggestions?|positive       |\n",
      "|$TSLA happy new year, 2020, everyone🍷🎉🙏                                                                                                 |negative       |\n",
      "|\"$TSLA haha just a collection of greats...\"\"Mars\"\" rofl 😈😎🌠⏫🔮💸👏💪🚀🎆🎇📣🎉🎊 *bork*\"                                                |negative       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Extract the first element from the result array\n",
    "extract_sentiment = udf(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None, StringType())\n",
    "result = result.withColumn(\"sentiment_label\", extract_sentiment(col(\"sentiment.result\")))\n",
    "\n",
    "# Show results\n",
    "result.select(\"tweet\", \"sentiment_label\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61744c1-1c85-41d9-b809-a4759712c346",
   "metadata": {},
   "source": [
    "## Aggregate Sentiment Scores per Ticker-Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fb6e93-fc8a-4cff-898b-b9e05905ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+----+---------------+-----+\n",
      "|ticker                                                   |date|sentiment_label|count|\n",
      "+---------------------------------------------------------+----+---------------+-----+\n",
      "| 116.50????? 😍🙏🏼\"                                     |null|null           |1    |\n",
      "| and obviously sales hit!                                |null|null           |1    |\n",
      "| nissan leaf                                             |null|negative       |1    |\n",
      "| lol ! 🖕\"                                               |null|null           |1    |\n",
      "| will drop down to 2500 📉📉📉 then it will rise to 4000\"|null|null           |1    |\n",
      "|null                                                     |null|null           |1119 |\n",
      "| still would be fine. it’s tesla. 💥\"                    |null|null           |1    |\n",
      "| overvalued                                              |null|positive       |1    |\n",
      "| up a lot today🚀🚀 🚀\"                                  |null|null           |1    |\n",
      "| plus lawsuits and higher taxes                          |null|negative       |1    |\n",
      "+---------------------------------------------------------+----+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "agg_df = result.groupBy(\"ticker\", \"date\", \"sentiment_label\").count().orderBy(\"date\")\n",
    "agg_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9438eef-232e-461e-9d5d-4a577f5cbf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+--------+-------+\n",
      "|ticker|      date|positive|negative|neutral|\n",
      "+------+----------+--------+--------+-------+\n",
      "|   bac|2020-07-16|       0|       1|      0|\n",
      "|   ccl|2020-11-13|       1|       1|      0|\n",
      "|  amzn|2020-08-05|       0|       2|      0|\n",
      "|    ba|2020-04-15|       4|       5|      0|\n",
      "|    ba|2020-12-22|       2|       0|      0|\n",
      "|  tsla|2020-11-11|       1|       2|      0|\n",
      "|  nvda|2020-12-01|       1|       0|      0|\n",
      "|  tsla|2020-01-13|       8|       1|      0|\n",
      "|    ba|2020-03-25|      20|      20|      0|\n",
      "|  tsla|2020-01-24|       5|       2|      0|\n",
      "+------+----------+--------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "pivot_df = agg_df.groupBy(\"ticker\", \"date\") \\\n",
    "    .pivot(\"sentiment_label\", [\"positive\", \"negative\", \"neutral\"]) \\\n",
    "    .sum(\"count\") \\\n",
    "    .fillna(0)\n",
    "\n",
    "pivot_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba43364-6825-4d6e-b696-0efd26eec220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+--------+-------+\n",
      "|ticker|      date|positive|negative|neutral|\n",
      "+------+----------+--------+--------+-------+\n",
      "|   bac|2020-07-16|       0|       1|      0|\n",
      "|   ccl|2020-11-13|       1|       1|      0|\n",
      "|  amzn|2020-08-05|       0|       2|      0|\n",
      "|    ba|2020-04-15|       4|       5|      0|\n",
      "|    ba|2020-12-22|       2|       0|      0|\n",
      "|  tsla|2020-11-11|       1|       2|      0|\n",
      "|  nvda|2020-12-01|       1|       0|      0|\n",
      "|  tsla|2020-01-13|       8|       1|      0|\n",
      "|    ba|2020-03-25|      20|      20|      0|\n",
      "|  tsla|2020-01-24|       5|       2|      0|\n",
      "|  sbux|2020-10-08|       0|       1|      0|\n",
      "|  baba|2020-12-03|       1|       0|      0|\n",
      "|    ma|2020-03-05|       0|       1|      0|\n",
      "|  tsla|2020-01-29|       7|      10|      0|\n",
      "|  tsla|2020-07-14|      14|      15|      0|\n",
      "|    fb|2020-07-07|       0|       2|      0|\n",
      "|    fb|2020-03-05|       1|       3|      0|\n",
      "|  baba|2020-02-12|       1|       1|      0|\n",
      "|     v|2020-03-18|       1|       0|      0|\n",
      "|   nke|2020-02-03|       0|       1|      0|\n",
      "|  msft|2020-03-03|       0|       2|      0|\n",
      "|  msft|2020-03-18|       0|       1|      0|\n",
      "|  amzn|2020-04-30|       2|       4|      0|\n",
      "|  aapl|2020-11-04|       3|       3|      0|\n",
      "|  aapl|2020-03-26|       3|       5|      0|\n",
      "|  nflx|2020-11-11|       1|       0|      0|\n",
      "|  baba|2020-12-22|       1|       3|      0|\n",
      "|    ba|2020-05-27|       2|       0|      0|\n",
      "|  aapl|2020-08-01|       2|       3|      0|\n",
      "|  aapl|2020-03-08|       0|       1|      0|\n",
      "|  goog|2020-10-20|       1|       0|      0|\n",
      "|   jnj|2020-12-04|       1|       0|      0|\n",
      "|  amzn|2020-04-22|       1|       0|      0|\n",
      "|  amzn|2020-10-06|       2|       0|      0|\n",
      "|  nflx|2020-04-13|       1|       0|      0|\n",
      "|   mcd|2020-10-24|       0|       1|      0|\n",
      "|  aapl|2020-02-19|       2|       1|      0|\n",
      "|  baba|2020-08-19|       1|       2|      0|\n",
      "|    fb|2020-02-12|       1|       0|      0|\n",
      "|   wmt|2020-07-14|       0|       1|      0|\n",
      "|  pypl|2020-10-21|       0|       0|      0|\n",
      "|    fb|2020-06-27|       3|       0|      0|\n",
      "|  amzn|2020-12-02|       1|       1|      0|\n",
      "|  baba|2020-11-12|       0|       2|      0|\n",
      "|  baba|2020-07-14|       0|       1|      0|\n",
      "|  amzn|2020-03-04|       0|       1|      0|\n",
      "|  tsla|2020-10-01|       8|      13|      0|\n",
      "|  abnb|2020-12-18|       1|       0|      0|\n",
      "|  aapl|2020-10-04|       2|       1|      0|\n",
      "|   pfe|2020-07-29|       1|       1|      0|\n",
      "|   dis|2020-05-09|       0|       2|      0|\n",
      "|   ccl|2020-04-07|       0|       4|      0|\n",
      "|  nflx|2020-02-04|       0|       2|      0|\n",
      "|  aapl|2020-11-29|       0|       1|      0|\n",
      "|  baba|2020-03-27|       1|       0|      0|\n",
      "|  aapl|2020-02-03|       1|       2|      0|\n",
      "|  baba|2020-03-24|       1|       0|      0|\n",
      "|   wmt|2020-10-13|       0|       1|      0|\n",
      "|  tsla|2020-11-06|       1|       4|      0|\n",
      "|   pfe|2020-10-21|       0|       1|      0|\n",
      "|    hd|2020-06-03|       1|       0|      0|\n",
      "|  tsla|2020-04-23|       0|       2|      0|\n",
      "|   nke|2020-08-19|       1|       0|      0|\n",
      "|  tsla|2020-01-18|       1|       4|      0|\n",
      "|  sbux|2020-02-13|       1|       0|      0|\n",
      "|  tsla|2020-10-28|       1|       4|      0|\n",
      "|   ups|2020-07-30|       2|       1|      0|\n",
      "|   ccl|2020-12-31|       0|       1|      0|\n",
      "|    ba|2020-03-12|       3|       5|      0|\n",
      "|  aapl|2020-01-23|       0|       3|      0|\n",
      "|  aapl|2020-10-12|       8|       9|      0|\n",
      "|  tsla|2020-08-27|      10|      16|      0|\n",
      "|  tsla|2020-10-09|       4|       7|      0|\n",
      "|  tsla|2020-02-22|       1|       1|      0|\n",
      "|    ba|2020-12-09|       0|       1|      0|\n",
      "|  amzn|2020-01-07|       1|       0|      0|\n",
      "|  baba|2020-12-25|       0|       0|      0|\n",
      "|  msft|2020-02-14|       1|       0|      0|\n",
      "|  pypl|2020-07-29|       0|       1|      0|\n",
      "|   pfe|2020-11-20|       1|       1|      0|\n",
      "|    fb|2020-06-29|       1|       0|      0|\n",
      "|    ba|2020-04-22|       0|       1|      0|\n",
      "|    ba|2020-03-11|       1|       6|      0|\n",
      "|   dis|2020-10-14|       1|       0|      0|\n",
      "|  tsla|2020-01-17|       9|       4|      0|\n",
      "|  nflx|2020-04-20|       1|       0|      0|\n",
      "|   ccl|2020-09-04|       0|       2|      0|\n",
      "|  msft|2020-10-24|       1|       0|      0|\n",
      "|  aapl|2020-06-19|       6|       1|      0|\n",
      "|  amzn|2020-09-22|       3|       3|      0|\n",
      "|   pfe|2020-04-09|       0|       1|      0|\n",
      "|     v|2020-07-11|       0|       1|      0|\n",
      "|  aapl|2020-09-18|      14|      13|      0|\n",
      "|  msft|2020-08-14|       1|       0|      0|\n",
      "|  msft|2020-07-17|       1|       2|      0|\n",
      "|   unh|2020-08-05|       1|       0|      0|\n",
      "| googl|2020-07-30|       0|       1|      0|\n",
      "|  tsla|2020-12-21|       5|       6|      0|\n",
      "|    ba|2020-07-14|       0|       2|      0|\n",
      "|  nflx|2020-10-07|       1|       0|      0|\n",
      "+------+----------+--------+--------+-------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "pivot_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a469f73-26ae-4d9d-a817-75f8d3977f6d",
   "metadata": {},
   "source": [
    "## Calculate Average Sentiment Score and Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51daea2-bc75-4929-b49d-d1e0f7c9e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------+------------+\n",
      "|ticker|      date|      avg_sentiment|tweet_volume|\n",
      "+------+----------+-------------------+------------+\n",
      "|  tsla|2020-01-13| 0.7777777777777778|           9|\n",
      "|  tsla|2020-01-24|0.42857142857142855|           7|\n",
      "|    ba|2020-03-25|                0.0|          41|\n",
      "|    ba|2020-04-15|-0.1111111111111111|           9|\n",
      "|   bac|2020-07-16|               -1.0|           1|\n",
      "|  amzn|2020-08-05|               -1.0|           2|\n",
      "|  tsla|2020-11-11|-0.3333333333333333|           3|\n",
      "|   ccl|2020-11-13|                0.0|           2|\n",
      "|  nvda|2020-12-01|                1.0|           1|\n",
      "|    ba|2020-12-22|                1.0|           2|\n",
      "+------+----------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, avg, count\n",
    "\n",
    "# Assign +1 to positive, -1 to negative, 0 to neutral\n",
    "result = result.withColumn(\n",
    "    \"sentiment_score\",\n",
    "    when(col(\"sentiment_label\") == \"positive\", 1)\n",
    "    .when(col(\"sentiment_label\") == \"negative\", -1)\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Aggregate avg sentiment and tweet volume per ticker-date\n",
    "avg_sentiment_df = result.groupBy(\"ticker\", \"date\").agg(\n",
    "    avg(\"sentiment_score\").alias(\"avg_sentiment\"),\n",
    "    count(\"tweet\").alias(\"tweet_volume\")\n",
    ")\n",
    "\n",
    "avg_sentiment_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cca322-1a38-421b-8f5e-a0d50d6c7663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+--------+-------+-------------------+------------+\n",
      "|ticker|      date|positive|negative|neutral|      avg_sentiment|tweet_volume|\n",
      "+------+----------+--------+--------+-------+-------------------+------------+\n",
      "|   bac|2020-07-16|       0|       1|      0|               -1.0|           1|\n",
      "|   ccl|2020-11-13|       1|       1|      0|                0.0|           2|\n",
      "|  amzn|2020-08-05|       0|       2|      0|               -1.0|           2|\n",
      "|    ba|2020-04-15|       4|       5|      0|-0.1111111111111111|           9|\n",
      "|    ba|2020-12-22|       2|       0|      0|                1.0|           2|\n",
      "|  tsla|2020-11-11|       1|       2|      0|-0.3333333333333333|           3|\n",
      "|  nvda|2020-12-01|       1|       0|      0|                1.0|           1|\n",
      "|  tsla|2020-01-13|       8|       1|      0| 0.7777777777777778|           9|\n",
      "|    ba|2020-03-25|      20|      20|      0|                0.0|          41|\n",
      "|  tsla|2020-01-24|       5|       2|      0|0.42857142857142855|           7|\n",
      "+------+----------+--------+--------+-------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_sentiment_df = pivot_df.join(avg_sentiment_df, on=[\"ticker\", \"date\"], how=\"left\")\n",
    "final_sentiment_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618fb821-520d-491e-a8f0-9a9b02b87fc0",
   "metadata": {},
   "source": [
    "## Load and Merge Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19400116-7993-44d3-b276-1c8e1c41fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- ticker: string (nullable = false)\n",
      "\n",
      "+----------+-----------------+-----------------+-----------------+-----------------+-----------------+---------+------+\n",
      "|      Date|             Open|             High|              Low|            Close|        Adj Close|   Volume|ticker|\n",
      "+----------+-----------------+-----------------+-----------------+-----------------+-----------------+---------+------+\n",
      "|2019-12-31|72.48249816894531|73.41999816894531|72.37999725341797| 73.4124984741211|71.52082061767578|100805600|  AAPL|\n",
      "|2020-01-02|74.05999755859375| 75.1500015258789|73.79750061035156| 75.0875015258789|73.15264892578125|135480400|  AAPL|\n",
      "|2020-01-03| 74.2874984741211| 75.1449966430664|           74.125|74.35749816894531|72.44145965576172|146322800|  AAPL|\n",
      "|2020-01-06|73.44750213623047|74.98999786376953|          73.1875|74.94999694824219| 73.0186767578125|118387200|  AAPL|\n",
      "|2020-01-07|74.95999908447266| 75.2249984741211|74.37000274658203|74.59750366210938|72.67527770996094|108872000|  AAPL|\n",
      "+----------+-----------------+-----------------+-----------------+-----------------+-----------------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "tickers = [\"AAPL\", \"TSLA\", \"AMZN\", \"DIS\", \"BA\", \"MSFT\"]\n",
    "stock_dfs = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    path = f\"hdfs:///stock-tweet-and-price/stockprice/{ticker}.csv\"\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(path)\n",
    "    df = df.withColumn(\"ticker\", lit(ticker))\n",
    "    stock_dfs.append(df)\n",
    "\n",
    "# Union all into one DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "stock_df = reduce(DataFrame.unionByName, stock_dfs)\n",
    "\n",
    "# Show schema and sample\n",
    "stock_df.printSchema()\n",
    "stock_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cbe8415-89ec-497e-8fa1-48ff03fc4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "\n",
    "final_sentiment_df = final_sentiment_df.withColumn(\"ticker\", upper(col(\"ticker\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30cce046-b118-4dce-8b39-89515e3ee7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Rename and format date\n",
    "stock_df = stock_df.withColumnRenamed(\"Date\", \"date\")\n",
    "stock_df = stock_df.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9b73ccd-73d4-4584-8e75-313df7d41507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join stock data with sentiment features\n",
    "merged_df = stock_df.join(final_sentiment_df, on=[\"ticker\", \"date\"], how=\"left\")\n",
    "\n",
    "# Fill NA for sentiment columns with defaults\n",
    "merged_df = merged_df.fillna({\n",
    "    \"positive\": 0,\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 0,\n",
    "    \"avg_sentiment\": 0.0,\n",
    "    \"tweet_volume\": 0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730dec1-867f-4d08-b3f3-0592feb3c216",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e202caf8-34d9-4f5b-aa2e-5e0d488dafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, avg, stddev\n",
    "\n",
    "w = Window.partitionBy(\"ticker\").orderBy(\"date\")\n",
    "\n",
    "merged_df = merged_df \\\n",
    "    .withColumn(\"lag_Close_1\", lag(\"Close\", 1).over(w)) \\\n",
    "    .withColumn(\"lag_sentiment_1\", lag(\"avg_sentiment\", 1).over(w)) \\\n",
    "    .withColumn(\"avg_Close_5\", avg(\"Close\").over(w.rowsBetween(-4, 0))) \\\n",
    "    .withColumn(\"volatility_5\", stddev(\"Close\").over(w.rowsBetween(-4, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dc700d9-43d4-40f0-a6cd-d2d6991cf245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+-------------------+------------+--------+--------+-------+-----------------+-------------------+-----------------+------------------+\n",
      "|ticker|      date|            Close|      avg_sentiment|tweet_volume|positive|negative|neutral|      lag_Close_1|    lag_sentiment_1|      avg_Close_5|      volatility_5|\n",
      "+------+----------+-----------------+-------------------+------------+--------+--------+-------+-----------------+-------------------+-----------------+------------------+\n",
      "|  AAPL|2019-12-31| 73.4124984741211|                0.0|           0|       0|       0|      0|             null|               null| 73.4124984741211|              null|\n",
      "|  AAPL|2020-01-02| 75.0875015258789|                0.0|           8|       4|       4|      0| 73.4124984741211|                0.0|            74.25|1.1844060164061108|\n",
      "|  AAPL|2020-01-03|74.35749816894531|-0.3333333333333333|           6|       2|       4|      0| 75.0875015258789|                0.0|74.28583272298177|0.8397980459362604|\n",
      "|  AAPL|2020-01-06|74.94999694824219|                0.0|           2|       1|       1|      0|74.35749816894531|-0.3333333333333333|74.45187377929688|0.7618742469514582|\n",
      "|  AAPL|2020-01-07|74.59750366210938|-0.3333333333333333|           3|       1|       2|      0|74.94999694824219|                0.0|74.48099975585937|0.6630089657610108|\n",
      "|  AAPL|2020-01-08|75.79750061035156|-0.6666666666666666|           6|       1|       5|      0|74.59750366210938|-0.3333333333333333|74.95800018310547|0.5504897881785514|\n",
      "|  AAPL|2020-01-09|77.40750122070312|               -0.5|           4|       1|       3|      0|75.79750061035156|-0.6666666666666666|75.42200012207032| 1.236826690180404|\n",
      "|  AAPL|2020-01-10| 77.5824966430664|               -0.5|           4|       1|       3|      0|77.40750122070312|               -0.5|76.06699981689454| 1.375992262295017|\n",
      "|  AAPL|2020-01-13|79.23999786376953|               -1.0|           4|       0|       4|      0| 77.5824966430664|               -0.5|           76.925|1.7827519772414326|\n",
      "|  AAPL|2020-01-14|78.16999816894531|              -0.25|           4|       1|       2|      0|79.23999786376953|               -1.0|77.63949890136719|1.2542982387515837|\n",
      "+------+----------+-----------------+-------------------+------------+--------+--------+-------+-----------------+-------------------+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.select(\n",
    "    \"ticker\", \"date\", \"Close\", \"avg_sentiment\", \"tweet_volume\", \n",
    "    \"positive\", \"negative\", \"neutral\", \n",
    "    \"lag_Close_1\", \"lag_sentiment_1\", \"avg_Close_5\", \"volatility_5\"\n",
    ").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d255dbe5-abb7-450e-a65f-274cd02e17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "merged_df = merged_df.withColumn(\n",
    "    \"has_sentiment\",\n",
    "    when(col(\"tweet_volume\") > 0, 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9534b603-2d58-4f23-862b-f7260e915cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+-----------------+-----------------+-----------------+-----------------+---------+--------+--------+-------+-------------------+------------+-----------------+-------------------+-----------------+------------------+-------------+\n",
      "|ticker|      date|             Open|             High|              Low|            Close|        Adj Close|   Volume|positive|negative|neutral|      avg_sentiment|tweet_volume|      lag_Close_1|    lag_sentiment_1|      avg_Close_5|      volatility_5|has_sentiment|\n",
      "+------+----------+-----------------+-----------------+-----------------+-----------------+-----------------+---------+--------+--------+-------+-------------------+------------+-----------------+-------------------+-----------------+------------------+-------------+\n",
      "|  AAPL|2019-12-31|72.48249816894531|73.41999816894531|72.37999725341797| 73.4124984741211|71.52082061767578|100805600|       0|       0|      0|                0.0|           0|             null|               null| 73.4124984741211|              null|            0|\n",
      "|  AAPL|2020-01-02|74.05999755859375| 75.1500015258789|73.79750061035156| 75.0875015258789|73.15264892578125|135480400|       4|       4|      0|                0.0|           8| 73.4124984741211|                0.0|            74.25|1.1844060164061108|            1|\n",
      "|  AAPL|2020-01-03| 74.2874984741211| 75.1449966430664|           74.125|74.35749816894531|72.44145965576172|146322800|       2|       4|      0|-0.3333333333333333|           6| 75.0875015258789|                0.0|74.28583272298177|0.8397980459362604|            1|\n",
      "|  AAPL|2020-01-06|73.44750213623047|74.98999786376953|          73.1875|74.94999694824219| 73.0186767578125|118387200|       1|       1|      0|                0.0|           2|74.35749816894531|-0.3333333333333333|74.45187377929688|0.7618742469514582|            1|\n",
      "|  AAPL|2020-01-07|74.95999908447266| 75.2249984741211|74.37000274658203|74.59750366210938|72.67527770996094|108872000|       1|       2|      0|-0.3333333333333333|           3|74.94999694824219|                0.0|74.48099975585937|0.6630089657610108|            1|\n",
      "|  AAPL|2020-01-08|74.29000091552734|76.11000061035156|74.29000091552734|75.79750061035156|73.84435272216797|132079200|       1|       5|      0|-0.6666666666666666|           6|74.59750366210938|-0.3333333333333333|74.95800018310547|0.5504897881785514|            1|\n",
      "|  AAPL|2020-01-09|76.80999755859375|77.60749816894531|76.55000305175781|77.40750122070312|75.41287994384766|170108400|       1|       3|      0|               -0.5|           4|75.79750061035156|-0.6666666666666666|75.42200012207032| 1.236826690180404|            1|\n",
      "|  AAPL|2020-01-10| 77.6500015258789| 78.1675033569336|          77.0625| 77.5824966430664|75.58334350585938|140644800|       1|       3|      0|               -0.5|           4|77.40750122070312|               -0.5|76.06699981689454| 1.375992262295017|            1|\n",
      "|  AAPL|2020-01-13|77.91000366210938|79.26750183105469| 77.7874984741211|79.23999786376953| 77.1981430053711|121532000|       0|       4|      0|               -1.0|           4| 77.5824966430664|               -0.5|           76.925|1.7827519772414326|            1|\n",
      "|  AAPL|2020-01-14|79.17500305175781|79.39250183105469| 78.0425033569336|78.16999816894531|76.15571594238281|161954400|       1|       2|      0|              -0.25|           4|79.23999786376953|               -1.0|77.63949890136719|1.2542982387515837|            1|\n",
      "+------+----------+-----------------+-----------------+-----------------+-----------------+-----------------+---------+--------+--------+-------+-------------------+------------+-----------------+-------------------+-----------------+------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145541b5-ce9d-4f85-8dfb-07181a688379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticker: string (nullable = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- positive: long (nullable = false)\n",
      " |-- negative: long (nullable = false)\n",
      " |-- neutral: long (nullable = false)\n",
      " |-- avg_sentiment: double (nullable = false)\n",
      " |-- tweet_volume: long (nullable = false)\n",
      " |-- lag_Close_1: double (nullable = true)\n",
      " |-- lag_sentiment_1: double (nullable = true)\n",
      " |-- avg_Close_5: double (nullable = true)\n",
      " |-- volatility_5: double (nullable = true)\n",
      " |-- has_sentiment: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c32d5-3a81-475d-a8fc-fd9189b80805",
   "metadata": {},
   "source": [
    "## Saving Final Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3801d8-8413-4c8c-90d8-43860b6e0247",
   "metadata": {},
   "source": [
    "## MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05c581-df4a-4bad-9549-1bb493d7b4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
